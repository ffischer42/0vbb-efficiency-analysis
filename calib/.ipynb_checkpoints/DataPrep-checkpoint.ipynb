{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"v07.01\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../src/init.jl\")\n",
    "include(\"../src/fct.jl\")\n",
    "include(\"../src/worker_fct.jl\")\n",
    "data_type = \"cal\"\n",
    "dataset = \"v07.01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort_data_all_01-new.jl\n",
    "For several runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "meta_key_file = \"datasets/run0053-run0114-cal-analysis.txt\";\n",
    "meta_keys = CSV.read(meta_key_file);\n",
    "channels = 0:1:36\n",
    "event_step = Int(1e4)\n",
    "\n",
    "current_dir = pwd()\n",
    "ddir = \"/remote/ceph/group/gerda/data/phase2/blind/\" * dataset * \"/gen/\"\n",
    "cd(ddir)\n",
    "filenames1 = []\n",
    "filenames4 = []\n",
    "for meta_key in meta_keys[1]\n",
    "    filename1 = ddir * glob(\"tier1/ged/\" * data_type * \"/\" * split(meta_key, \"-\")[2] * \"/\" * meta_key * \"*.root\")[1]\n",
    "    filename4 = ddir * glob(\"tier4/all/\" * data_type * \"/\" * split(meta_key, \"-\")[2] * \"/\" * meta_key * \"*.root\")[1]\n",
    "    push!(filenames1, filename1)\n",
    "    push!(filenames4, filename4)\n",
    "end\n",
    "cd(current_dir)\n",
    "\n",
    "if data_type == \"phy\"\n",
    "    base_path = \"pulses/data/raw_\" * dataset * \"/\"\n",
    "elseif data_type == \"cal\"\n",
    "    base_path = \"pulses/calib/raw_\" * dataset * \"/\"\n",
    "end\n",
    "log_file = base_path * \"log.json\"\n",
    "if !isdir(base_path)\n",
    "    mkpath(base_path)\n",
    "end\n",
    "if !isfile(log_file)\n",
    "    open(log_file, \"w\") do f\n",
    "        JSON.print(f, Dict(), 4)\n",
    "    end\n",
    "    global log = Dict()\n",
    "else\n",
    "    global log = JSON.parsefile(log_file)\n",
    "end;\n",
    "\n",
    "for i in eachindex(filenames4)\n",
    "    start_t = now()\n",
    "    run = parse(Int64, split(split(filenames4[i], \"gerda-run\")[2], \"-\")[1])\n",
    "    filename1 = filenames1[i]\n",
    "    filename4 = filenames4[i]\n",
    "    \n",
    "    @info(\"Run \" * string(run) * \" | file \" * string(i) * \" of total \" * string(length(filenames4)))\n",
    "    log = JSON.parsefile(log_file)\n",
    "    if length(keys(log)) >= 1\n",
    "        estimation = 0\n",
    "        for k in keys(log)\n",
    "            estimation += log[k]\n",
    "        end\n",
    "        estimation /= length(keys(log))\n",
    "        fileinfo = stat(filename4)\n",
    "        est_t = round(fileinfo.size * estimation / 60, digits=1)\n",
    "        @info(\"Estimated time for this file: \" * string(est_t) * \" min\")\n",
    "        total_filesize = 0\n",
    "        for f in i:length(filenames4)\n",
    "            total_filesize += stat(filenames4[f]).size\n",
    "        end\n",
    "        est_t = total_filesize * estimation / 60\n",
    "        unit = \" s\"\n",
    "        if est_t/60/60/24 > 1\n",
    "            est_t /= 60*60*24\n",
    "            unit = \" d\"\n",
    "        elseif est_t/60/60 > 1\n",
    "            est_t /= 60*60\n",
    "            unit = \" h\"\n",
    "        elseif est_t/60 > 1\n",
    "            est_t /= 60\n",
    "            unit = \" min\"\n",
    "        end\n",
    "        @info(\"Estimated time till completion: \" * string(round(est_t, digits=1)) * unit)\n",
    "    end\n",
    "    @info(\"------------------------------\")\n",
    "    \n",
    "\n",
    "    if true#!(filename4 in keys(JSON.parsefile(log_file)))\n",
    "        @info(\"Load Tier4\")\n",
    "        @time tier4 = Table(TFile(filename4)[\"tier4\"]);\n",
    "        temp_E = sum.(tier4.energy[:])\n",
    "\n",
    "        index_1 = findall(x->x == 1, tier4.multiplicity[:])\n",
    "        index_2 = findall(y->y > 300, temp_E[index_1])\n",
    "        index_3 = findall(x->x == 0, tier4.isBL[index_1[index_2]])\n",
    "        index_4 = findall(x->x == 0, tier4.isTP[index_1[index_2[index_3]]])\n",
    "        filtered_index = index_1[index_2[index_3[index_4]]]\n",
    "        if length(filtered_index) > 0\n",
    "            @info(\"Number of events: \" * string(length(temp_E)))\n",
    "            @info(\"Number of events after filter: \" * string(length(filtered_index)))\n",
    "            steps = []\n",
    "            s = 1\n",
    "            while s <= length(filtered_index)\n",
    "                a = s\n",
    "                b = s + event_step - 1 <= length(filtered_index) ? s+event_step-1 : length(filtered_index)\n",
    "#                 println(string(filtered_index[a]) * \" - \" * string(filtered_index[b]))\n",
    "                push!(steps, [a,b])\n",
    "                s += event_step\n",
    "            end\n",
    "            return steps\n",
    "            for s in steps\n",
    "                result = Table( energy       = [],\n",
    "                        run          = [],\n",
    "                        channel      = [],\n",
    "                        AEvetoed     = [],\n",
    "                        datasetID    = [],\n",
    "                        AEclassifier = [],\n",
    "                        waveform     = [])\n",
    "                IJulia.clear_output(true)\n",
    "                run_str = split(basename(filename4), \"-\")[2]\n",
    "                @info(\"Run \" * run_str * \" | file \" * string(i) * \" of total \" * string(length(filenames4)))\n",
    "                @info(\"Step \" * string(findfirst(x->x == s, steps)) * \" of \" * string(length(steps)))\n",
    "                file = base_path * run_str * \"/\"\n",
    "                if !isdir(file)\n",
    "                    mkpath(file)\n",
    "                end\n",
    "                file *= basename(filename4) * lpad(findfirst(x->x == s, steps), 4, \"0\") * \".h5\"\n",
    "                if !isfile(file)\n",
    "                    \n",
    "                    tmp = filtered_index[s[1]:s[2]]\n",
    "                    @info(\"Event \" * string(tmp[1]) * \" until \" * string(tmp[end]))\n",
    "                    tier4 = Table(TFile(filename4)[\"tier4\"])[tmp];\n",
    "                    @info(\"Load Tier1\")\n",
    "                    @time treeTier1 = TFile(filename1)[\"MGTree\"].event;\n",
    "                    @info(\"Apply first filter to Tier1 & Tier4\")\n",
    "                    @time waveforms = TypedTables.Table(raw2mgtevent.(treeTier1[tmp])).fAuxWaveforms\n",
    "        #             waveforms = waveforms[tmp]\n",
    "                    if length(tmp) > 0\n",
    "                        run_str = split(basename(filename4), \"-\")[2]\n",
    "                        run = parse(Int64, split(run_str, \"run\")[2])\n",
    "\n",
    "                        pro = Progress(length(channels), dt=0.5,\n",
    "                            barglyphs=BarGlyphs('|','█', ['▁' ,'▂' ,'▃' ,'▄' ,'▅' ,'▆', '▇'],' ','|',),\n",
    "                            barlen=10);\n",
    "                        for ch in channels\n",
    "\n",
    "                            tmp = findall(y->y[ch + 1] != 0, tier4.energy)\n",
    "                            if length(tmp) > 0\n",
    "                                waveform = []\n",
    "                                for i in tmp\n",
    "                                    if data_type == \"phy\"\n",
    "                                        push!(waveform, waveforms[i][ch + 1].wf)\n",
    "                                    else\n",
    "                                        push!(waveform, waveforms[i][1].wf)\n",
    "                                    end\n",
    "                                end\n",
    "\n",
    "                                AEvetoed     = []\n",
    "                                datasetID    = []\n",
    "                                AEclassifier = []\n",
    "                                for i in tmp\n",
    "                                    push!(AEvetoed,     tier4[i].isAoEvetoed[ch+1])\n",
    "                                    push!(datasetID,    tier4[i].datasetID[ch+1])\n",
    "                                    push!(AEclassifier, tier4[i].AoEclassifier[ch+1])\n",
    "                                end\n",
    "\n",
    "                                append!(result, Table(  energy       = sum.(tier4.energy[tmp]),\n",
    "                                                        run          = Int.(zeros(length(tmp)) .+ run),\n",
    "                                                        channel      = Int.(zeros(length(tmp)) .+ ch),\n",
    "                                                        AEvetoed     = AEvetoed,\n",
    "                                                        datasetID    = datasetID,\n",
    "                                                        AEclassifier = AEclassifier,\n",
    "                                                        waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(waveform))))\n",
    "                            end\n",
    "                            next!(pro)\n",
    "                        end\n",
    "                    end\n",
    "                    if size(result,1) > 0\n",
    "                        file = base_path * run_str * \"/\"\n",
    "                        file *= basename(filename4) * lpad(findfirst(x->x == s, steps), 4, \"0\") * \".h5\"\n",
    "                        HDF5.h5open(file, \"w\") do h5f\n",
    "                            LegendHDF5IO.writedata( h5f, \"data\", Table( energy       = float.(result.energy),\n",
    "                                                                        run          = Int.(result.run),\n",
    "                                                                        channel      = Int.(result.channel),\n",
    "                                                                        AEvetoed     = Int.(result.AEvetoed),\n",
    "                                                                        datasetID    = Int.(result.datasetID),\n",
    "                                                                        AEclassifier = float.(result.AEclassifier),\n",
    "                                                                        waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(result.waveform))))\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "            log = JSON.parsefile(log_file)\n",
    "            dt = now() - start_t\n",
    "            fileinfo = stat(filenames4[1])\n",
    "            fileinfo.size\n",
    "            log[filename4] = (dt.value / 1000) / fileinfo.size\n",
    "            open(log_file, \"w\") do f\n",
    "                JSON.print(f, log, 4)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    IJulia.clear_output(true)\n",
    "#     Base.run(`clear`)\n",
    "    log = JSON.parsefile(log_file)\n",
    "    @info(string(length(log)) * \" of \" * string(length(filenames4)) * \" done!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into detectors (Sep 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   0%|          |  ETA: 2:53:36\u001b[39m"
     ]
    }
   ],
   "source": [
    "if data_type == \"phy\"\n",
    "    plots_base_path = \"../../waveforms/data/plots/raw_\" * dataset * \"/\"\n",
    "    base_path_raw   = \"../../waveforms/data/raw_\" * dataset * \"/\"\n",
    "    base_path       = \"../../waveforms/data/\" * dataset * \"/\"\n",
    "elseif data_type == \"cal\"\n",
    "    plots_base_path = \"../../waveforms/calib/plots/raw_\" * dataset * \"/\"\n",
    "    base_path_raw   = \"../../waveforms/calib/raw_\" * dataset * \"/\"\n",
    "    base_path       = \"../../waveforms/calib/\" * dataset * \"/\"\n",
    "end\n",
    "number_of_pulses = 1e4\n",
    "bl_range = 1:1:200\n",
    "\n",
    "\n",
    "files = glob(base_path_raw * \"*/*.h5\");\n",
    "data_cal = Dict()\n",
    "for ch in 0:1:36\n",
    "    data_cal[string(ch)] = Dict()\n",
    "    data_cal[string(ch)][\"data\"] = Table(energy = [], run = [], channel = [], AoEvetoed = [], datasetID = [], AoEclassifier = [], A = [], E = [], waveform = [])\n",
    "    data_cal[string(ch)][\"counter\"] = 1\n",
    "end\n",
    "pro = Progress(length(files), dt=0.5,\n",
    "                barglyphs=BarGlyphs('|','█', ['▁' ,'▂' ,'▃' ,'▄' ,'▅' ,'▆', '▇'],' ','|',),\n",
    "                barlen=10);\n",
    "for file in files[1:10]\n",
    "    if stat(file).size > 1000\n",
    "        data = HDF5.h5open(file, \"r\") do h5f\n",
    "            LegendHDF5IO.readdata(h5f, \"data\")\n",
    "        end;\n",
    "        for ch in unique(data.channel)\n",
    "            ch_str = lpad(ch, 2, \"0\");\n",
    "            temp = data |> @filter(_.channel == ch) |> Table\n",
    "            waveforms = []\n",
    "            A = []\n",
    "            E = []\n",
    "            for wf in temp.waveform\n",
    "                pulse   = -1 .*float.(wf.value)\n",
    "                pulse .-= sum(pulse[bl_range])/length(bl_range)\n",
    "                push!(A, maximum(multi_mwa(diff(pulse),5,3)))\n",
    "                push!(E, maximum(multi_mwa(diff(pulse),201,6)))\n",
    "                push!(waveforms, RDWaveform(wf.time, pulse))\n",
    "            end\n",
    "            \n",
    "            append!(data_cal[string(ch)][\"data\"], Table(energy   = temp.energy,\n",
    "                                                        run      = temp.run,\n",
    "                                                        channel  = temp.channel,\n",
    "                                                        AoEvetoed= temp.AEvetoed,\n",
    "                                                        datasetID= temp.datasetID,\n",
    "                                                        AoEclassifier = temp.AEclassifier,\n",
    "                                                        A        = A,\n",
    "                                                        E        = E,\n",
    "                                                        waveform = waveforms))\n",
    "            if size(data_cal[string(ch)][\"data\"],1) >= number_of_pulses\n",
    "                filename = base_path * channel_to_name[ch] * \"-\" * ch_str * \"/\"\n",
    "                !isdir(filename) ? mkpath(filename) : \"path exists\"\n",
    "                filename *= string(data_cal[string(ch)][\"counter\"]) * \".h5\"\n",
    "                data_cal[string(ch)][\"counter\"] += 1\n",
    "                HDF5.h5open(filename, \"w\") do h5f\n",
    "                    LegendHDF5IO.writedata( h5f, \"data\", Table( energy       = float.(data_cal[string(ch)][\"data\"].energy),\n",
    "                                                                run          = Int.(data_cal[string(ch)][\"data\"].run),\n",
    "                                                                channel      = Int.(data_cal[string(ch)][\"data\"].channel),\n",
    "                                                                AoEvetoed    = Int.(data_cal[string(ch)][\"data\"].AoEvetoed),\n",
    "                                                                datasetID    = Int.(data_cal[string(ch)][\"data\"].datasetID),\n",
    "                                                                AoEclassifier= float.(data_cal[string(ch)][\"data\"].AoEclassifier),\n",
    "                                                                A            = float.(data_cal[string(ch)][\"data\"].A),\n",
    "                                                                E            = float.(data_cal[string(ch)][\"data\"].E),\n",
    "                                                                waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(data_cal[string(ch)][\"data\"].waveform))))\n",
    "                end\n",
    "                data_cal[string(ch)][\"data\"] = Table(energy = [], run = [], channel = [], AoEvetoed = [], datasetID = [], AoEclassifier = [], A = [], E = [], waveform = [])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    next!(pro)\n",
    "end\n",
    "for ch in 0:1:36\n",
    "    ch_str = lpad(ch, 2, \"0\");\n",
    "    if size(data_cal[string(ch)][\"data\"],1) > 0\n",
    "        filename = base_path * channel_to_name[ch] * \"-\" * ch_str * \"/\"\n",
    "        !isdir(filename) ? mkpath(filename) : \"path exists\"\n",
    "        filename *= lpad(data_cal[string(ch)][\"counter\"], 4, \"0\") * \".h5\"\n",
    "        data_cal[string(ch)][\"counter\"] += 1\n",
    "        HDF5.h5open(filename, \"w\") do h5f\n",
    "            LegendHDF5IO.writedata( h5f, \"data\", Table( energy       = float.(data_cal[string(ch)][\"data\"].energy),\n",
    "                                                        run          = Int.(data_cal[string(ch)][\"data\"].run),\n",
    "                                                        channel      = Int.(data_cal[string(ch)][\"data\"].channel),\n",
    "                                                        AoEvetoed     = Int.(data_cal[string(ch)][\"data\"].AoEvetoed),\n",
    "                                                        datasetID    = float.(data_cal[string(ch)][\"data\"].datasetID),\n",
    "                                                        AoEclassifier= float.(data_cal[string(ch)][\"data\"].AoEclassifier),\n",
    "                                                        A            = float.(data_cal[string(ch)][\"data\"].A),\n",
    "                                                        E            = float.(data_cal[string(ch)][\"data\"].E),\n",
    "                                                        waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(data_cal[string(ch)][\"data\"].waveform))))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get calibration constant for each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.2",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
