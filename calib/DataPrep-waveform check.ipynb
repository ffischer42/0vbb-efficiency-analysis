{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"../src/init.jl\")\n",
    "include(\"../src/fct.jl\")\n",
    "include(\"../src/worker_fct.jl\")\n",
    "try using UpROOT\n",
    "catch\n",
    "    Pkg.add(\"UpROOT\")\n",
    "    using UpROOT\n",
    "end\n",
    "try using LegendUpROOTIO\n",
    "catch\n",
    "    Pkg.add(url=\"https://github.com/legend-exp/LegendUpROOTIO.jl\")\n",
    "    using LegendUpROOTIO\n",
    "end\n",
    "using LegendUpROOTIO: read_mgtevent, raw2mgtevent, mgdo2legend\n",
    "using DataFrames\n",
    "data_type = \"cal\"\n",
    "dataset = \"v07.01\"\n",
    "current_dir = pwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sort_data_all_01-new.jl\n",
    "For several runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd(current_dir)\n",
    "meta_key_file = \"../datasets/run0083-run0092-cal-analysis.txt\";\n",
    "meta_keys = open(meta_key_file, \"r\") do f\n",
    "    readlines(f)\n",
    "end\n",
    "channels = 0:1:36\n",
    "event_step = Int(1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_keys[1]\n",
    "auxWaveforms, waveforms = [], []\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ddir = \"/remote/ceph/group/gerda/data/phase2/blind/\" * dataset * \"/gen/\"\n",
    "cd(ddir)\n",
    "filenames1 = []\n",
    "filenames4 = []\n",
    "for meta_key in meta_keys\n",
    "    filename1 = ddir * glob(\"tier1/ged/\" * data_type * \"/\" * split(meta_key, \"-\")[2] * \"/\" * meta_key * \"*.root\")[1]\n",
    "    filename4 = ddir * glob(\"tier4/all/\" * data_type * \"/\" * split(meta_key, \"-\")[2] * \"/\" * meta_key * \"*.root\")[1]\n",
    "    push!(filenames1, filename1)\n",
    "    push!(filenames4, filename4)\n",
    "end\n",
    "cd(current_dir)\n",
    "\n",
    "if data_type == \"phy\"\n",
    "    base_path = \"pulses/data/raw_\" * dataset * \"/\"\n",
    "elseif data_type == \"cal\"\n",
    "    base_path = \"../../waveforms/test/calib/raw_\" * dataset * \"/\"\n",
    "end\n",
    "log_file = base_path * \"log.json\"\n",
    "!isdir(base_path) ? mkpath(base_path) : \"\"\n",
    "\n",
    "for i in eachindex(filenames4)\n",
    "    start_t = now()\n",
    "    run = parse(Int64, split(split(filenames4[i], \"gerda-run\")[2], \"-\")[1])\n",
    "    filename1 = filenames1[i]\n",
    "    filename4 = filenames4[i]\n",
    "    \n",
    "    @info(\"Run \" * string(run) * \" | file \" * string(i) * \" of total \" * string(length(filenames4)))\n",
    "    @info(\"------------------------------\")\n",
    "    \n",
    "\n",
    "    if true\n",
    "        @info(\"Load Tier4\")\n",
    "        @time tier4 = Table(TFile(filename4)[\"tier4\"]);\n",
    "        temp_E = sum.(tier4.energy[:])\n",
    "\n",
    "        index_1 = findall(x->x == 1, tier4.multiplicity[:])\n",
    "        index_2 = findall(y->y > 300, temp_E[index_1])\n",
    "        index_3 = findall(x->x == 0, tier4.isBL[index_1[index_2]])\n",
    "        index_4 = findall(x->x == 0, tier4.isTP[index_1[index_2[index_3]]])\n",
    "        filtered_index = index_1[index_2[index_3[index_4]]]\n",
    "        if length(filtered_index) > 0\n",
    "            @info(\"Number of events: \" * string(length(temp_E)))\n",
    "            @info(\"Number of events after filter: \" * string(length(filtered_index)))\n",
    "            steps = []\n",
    "            s = 1\n",
    "            while s <= length(filtered_index)\n",
    "                a = s\n",
    "                b = s + event_step - 1 <= length(filtered_index) ? s+event_step-1 : length(filtered_index)\n",
    "#                 println(string(filtered_index[a]) * \" - \" * string(filtered_index[b]))\n",
    "                push!(steps, [a,b])\n",
    "                s += event_step\n",
    "            end\n",
    "            for s in steps\n",
    "                result = Table( energy       = [],\n",
    "                        run          = [],\n",
    "                        channel      = [],\n",
    "                        AEvetoed     = [],\n",
    "                        datasetID    = [],\n",
    "                        AEclassifier = [],\n",
    "                        auxWaveform  = [],\n",
    "                        waveform     = [])\n",
    "                IJulia.clear_output(true)\n",
    "                run_str = split(basename(filename4), \"-\")[2]\n",
    "                @info(\"Run \" * run_str * \" | file \" * string(i) * \" of total \" * string(length(filenames4)))\n",
    "                @info(\"Step \" * string(findfirst(x->x == s, steps)) * \" of \" * string(length(steps)))\n",
    "                file = base_path * run_str * \"/\"\n",
    "                if !isdir(file)\n",
    "                    mkpath(file)\n",
    "                end\n",
    "                file *= basename(filename4) * lpad(findfirst(x->x == s, steps), 4, \"0\") * \".h5\"\n",
    "                if !isfile(file)\n",
    "                    \n",
    "                    tmp = filtered_index[s[1]:s[2]]\n",
    "                    @info(\"Event \" * string(tmp[1]) * \" until \" * string(tmp[end]))\n",
    "                    tier4 = Table(TFile(filename4)[\"tier4\"])[tmp];\n",
    "                    @info(\"Load Tier1\")\n",
    "                    @time treeTier1 = TFile(filename1)[\"MGTree\"].event;\n",
    "                    @info(\"Apply first filter to Tier1 & Tier4\")\n",
    "                    treeTier1 = TypedTables.Table(raw2mgtevent.(treeTier1[tmp]))\n",
    "                    @time auxWaveforms = treeTier1.fAuxWaveforms\n",
    "                    @time waveforms = treeTier1.fWaveforms\n",
    "                    if length(tmp) > 0\n",
    "                        run_str = split(basename(filename4), \"-\")[2]\n",
    "                        run = parse(Int64, split(run_str, \"run\")[2])\n",
    "\n",
    "                        @showprogress for ch in channels\n",
    "\n",
    "                            tmp = findall(y->y[ch + 1] != 0, tier4.energy)\n",
    "                            if length(tmp) > 0\n",
    "                                auxWaveform = []\n",
    "                                waveform = []\n",
    "                                for i in tmp\n",
    "                                    if data_type == \"phy\"\n",
    "                                        push!(auxWaveform, auxWaveforms[i][ch + 1].wf)\n",
    "                                        push!(waveform, waveforms[i][ch + 1].wf)\n",
    "                                    else\n",
    "                                        push!(auxWaveform, auxWaveforms[i][1].wf)\n",
    "                                        push!(waveform, waveforms[i][1].wf)\n",
    "                                    end\n",
    "                                end\n",
    "\n",
    "                                AEvetoed     = []\n",
    "                                datasetID    = []\n",
    "                                AEclassifier = []\n",
    "                                for i in tmp\n",
    "                                    push!(AEvetoed,     tier4[i].isAoEvetoed[ch+1])\n",
    "                                    push!(datasetID,    tier4[i].datasetID[ch+1])\n",
    "                                    push!(AEclassifier, tier4[i].AoEclassifier[ch+1])\n",
    "                                end\n",
    "\n",
    "                                append!(result, Table(  energy       = sum.(tier4.energy[tmp]),\n",
    "                                                        run          = Int.(zeros(length(tmp)) .+ run),\n",
    "                                                        channel      = Int.(zeros(length(tmp)) .+ ch),\n",
    "                                                        AEvetoed     = AEvetoed,\n",
    "                                                        datasetID    = datasetID,\n",
    "                                                        AEclassifier = AEclassifier,\n",
    "                                                        auxWaveform  = StructArray{RDWaveform}(Array{RDWaveform,1}(auxWaveform)),\n",
    "                                                        waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(waveform))\n",
    "                                        )\n",
    "                                )\n",
    "                            end\n",
    "                        end\n",
    "                    end\n",
    "                    if size(result,1) > 0\n",
    "                        file = base_path * run_str * \"/\"\n",
    "                        file *= basename(filename4) * lpad(findfirst(x->x == s, steps), 4, \"0\") * \".h5\"\n",
    "                        HDF5.h5open(file, \"w\") do h5f\n",
    "                            LegendHDF5IO.writedata( h5f, \"data\", Table( energy       = float.(result.energy),\n",
    "                                                                        run          = Int.(result.run),\n",
    "                                                                        channel      = Int.(result.channel),\n",
    "                                                                        AEvetoed     = Int.(result.AEvetoed),\n",
    "                                                                        datasetID    = Int.(result.datasetID),\n",
    "                                                                        AEclassifier = float.(result.AEclassifier),\n",
    "                                                                        auxWaveform  = StructArray{RDWaveform}(Array{RDWaveform,1}(result.auxWaveform)),\n",
    "                                                                        waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(result.waveform))))\n",
    "                        end\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    IJulia.clear_output(true)\n",
    "#     Base.run(`clear`)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into detectors (Nov 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function main(args)\n",
    "#     return args\n",
    "# end\n",
    "# Load inline arguments for worker unit\n",
    "# num_workers, this = main(ARGS)\n",
    "num_workers = 1#parse(Int64, num_workers)\n",
    "this = 1#parse(Int64, this)\n",
    "\n",
    "println(\"Worker \" * string(this) * \" of \" * string(num_workers))\n",
    "#\n",
    "# Load packages and functions\n",
    "include(\"../src/init.jl\")\n",
    "include(\"../src/fct.jl\")\n",
    "include(\"../src/worker_fct.jl\")\n",
    "data_type = \"cal\" # phy\n",
    "dataset = \"v07.01\"\n",
    "\n",
    "if data_type == \"phy\"\n",
    "    plots_base_path = \"../../waveforms/data/plots/raw_\" * dataset * \"/\"\n",
    "    base_path_raw   = \"../../waveforms/data/raw_\" * dataset * \"/\"\n",
    "    base_path       = \"../../waveforms/data/\" * dataset * \"/\"\n",
    "elseif data_type == \"cal\"\n",
    "    plots_base_path = \"../../waveforms/calib/plots/raw_\" * dataset * \"/\"\n",
    "    base_path_raw   = \"../../waveforms/calib/raw_\" * dataset * \"/\"\n",
    "    base_path       = \"../../waveforms/calib/\" * dataset * \"/\"\n",
    "end\n",
    "number_of_pulses = 1e4\n",
    "bl_range = 1:1:200\n",
    "\n",
    "\n",
    "files = glob(base_path_raw * \"*/*.h5\");\n",
    "files = get_share_for_worker(files, num_workers, this)\n",
    "\n",
    "data_cal = Dict()\n",
    "for ch in [19]#0:1:36\n",
    "    data_cal[string(ch)] = Dict()\n",
    "    data_cal[string(ch)][\"data\"] = Table(energy = [], run = [], channel = [], AoEvetoed = [], datasetID = [], AoEclassifier = [], A = [], E = [], waveform = [])\n",
    "    data_cal[string(ch)][\"counter\"] = 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro = Progress(length(files), dt=0.5,\n",
    "                barglyphs=BarGlyphs('|','█', ['▁' ,'▂' ,'▃' ,'▄' ,'▅' ,'▆', '▇'],' ','|',),\n",
    "                barlen=10);\n",
    "for file in files\n",
    "    if stat(file).size > 1000\n",
    "        data = HDF5.h5open(file, \"r\") do h5f\n",
    "            LegendHDF5IO.readdata(h5f, \"data\")\n",
    "        end;\n",
    "        for ch in [19]#unique(data.channel)\n",
    "            ch_str = lpad(ch, 2, \"0\");\n",
    "            temp = data |> @filter(_.channel == ch) |> Table\n",
    "#             cal_factor = cal[string(ch)][\"value\"]\n",
    "            waveforms = []\n",
    "            A = []\n",
    "            E = []\n",
    "            for wf in temp.waveform\n",
    "                pulse   = -1 .*float.(wf.value)\n",
    "                pulse .-= sum(pulse[bl_range])/length(bl_range)\n",
    "#                 pulse .*= cal_factor\n",
    "                push!(A, maximum(multi_mwa(diff(pulse),5,3)))\n",
    "                push!(E, maximum(multi_mwa(diff(pulse),201,6)))\n",
    "                push!(waveforms, RDWaveform(wf.time, pulse))\n",
    "            end\n",
    "            \n",
    "            append!(data_cal[string(ch)][\"data\"], Table(energy   = temp.energy,\n",
    "                                                        run      = temp.run,\n",
    "                                                        channel  = temp.channel,\n",
    "                                                        AoEvetoed= temp.AEvetoed,\n",
    "                                                        datasetID= temp.datasetID,\n",
    "                                                        AoEclassifier = temp.AEclassifier,\n",
    "                                                        A        = A,\n",
    "                                                        E        = E,\n",
    "                                                        waveform = waveforms))\n",
    "            if size(data_cal[string(ch)][\"data\"],1) >= number_of_pulses\n",
    "                filename = base_path *  ch_str * \"-\" * channel_to_name[ch] * \"/\"\n",
    "                !isdir(filename) ? mkpath(filename) : \"path exists\"\n",
    "                filename *= lpad(data_cal[string(ch)][\"counter\"], 4, \"0\") * \".h5\"\n",
    "                data_cal[string(ch)][\"counter\"] += 1\n",
    "                HDF5.h5open(filename, \"w\") do h5f\n",
    "                    LegendHDF5IO.writedata( h5f, \"data\", Table( energy       = float.(data_cal[string(ch)][\"data\"].energy),\n",
    "                                                                run          = Int.(data_cal[string(ch)][\"data\"].run),\n",
    "                                                                channel      = Int.(data_cal[string(ch)][\"data\"].channel),\n",
    "                                                                AoEvetoed    = Int.(data_cal[string(ch)][\"data\"].AoEvetoed),\n",
    "                                                                datasetID    = Int.(data_cal[string(ch)][\"data\"].datasetID),\n",
    "                                                                AoEclassifier= float.(data_cal[string(ch)][\"data\"].AoEclassifier),\n",
    "                                                                A            = float.(data_cal[string(ch)][\"data\"].A),\n",
    "                                                                E            = float.(data_cal[string(ch)][\"data\"].E),\n",
    "                                                                waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(data_cal[string(ch)][\"data\"].waveform))))\n",
    "                end\n",
    "                data_cal[string(ch)][\"data\"] = Table(energy = [], run = [], channel = [], AoEvetoed = [], datasetID = [], AoEclassifier = [], A = [], E = [], waveform = [])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    next!(pro)\n",
    "end\n",
    "for ch in [19]#0:1:36\n",
    "    ch_str = lpad(ch, 2, \"0\");\n",
    "    if size(data_cal[string(ch)][\"data\"],1) > 0\n",
    "        filename = base_path *  ch_str * \"-\" * channel_to_name[ch] * \"/\"\n",
    "        !isdir(filename) ? mkpath(filename) : \"path exists\"\n",
    "        filename *= lpad(data_cal[string(ch)][\"counter\"], 4, \"0\") * \".h5\"\n",
    "        data_cal[string(ch)][\"counter\"] += 1\n",
    "        HDF5.h5open(filename, \"w\") do h5f\n",
    "            LegendHDF5IO.writedata( h5f, \"data\", Table( energy       = float.(data_cal[string(ch)][\"data\"].energy),\n",
    "                                                        run          = Int.(data_cal[string(ch)][\"data\"].run),\n",
    "                                                        channel      = Int.(data_cal[string(ch)][\"data\"].channel),\n",
    "                                                        AoEvetoed     = Int.(data_cal[string(ch)][\"data\"].AoEvetoed),\n",
    "                                                        datasetID    = float.(data_cal[string(ch)][\"data\"].datasetID),\n",
    "                                                        AoEclassifier= float.(data_cal[string(ch)][\"data\"].AoEclassifier),\n",
    "                                                        A            = float.(data_cal[string(ch)][\"data\"].A),\n",
    "                                                        E            = float.(data_cal[string(ch)][\"data\"].E),\n",
    "                                                        waveform     = StructArray{RDWaveform}(Array{RDWaveform,1}(data_cal[string(ch)][\"data\"].waveform))))\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tl FEP calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function main(args)\n",
    "#     return args\n",
    "# end\n",
    "# Load inline arguments for worker unit\n",
    "# num_workers, this = main(ARGS)\n",
    "num_workers = 1#parse(Int64, num_workers)\n",
    "this = 1#parse(Int64, this)\n",
    "\n",
    "println(\"Worker \" * string(this) * \" of \" * string(num_workers))\n",
    "#\n",
    "# Load packages and functions\n",
    "include(\"../src/init.jl\")\n",
    "include(\"../src/fct.jl\")\n",
    "include(\"../src/fitting-fct.jl\")\n",
    "include(\"../src/worker_fct.jl\")\n",
    "data_type = \"cal\" # phy\n",
    "dataset = \"v07.01\"\n",
    "\n",
    "plots_base_path = \"../../waveforms/calib/plots/\" * dataset * \"/\"\n",
    "base_path_raw   = \"../../waveforms/calib/raw_\" * dataset * \"/\"\n",
    "base_path       = \"../../waveforms/calib/\" * dataset * \"/\"\n",
    "base_path_fep   = \"../../waveforms/calib/\" * dataset * \"_Tl_FEP/\"\n",
    "cal = JSON.parsefile(\"../dicts/A_cal.json\")\n",
    "E  = 2614.5;    \n",
    "ΔE = 1;\n",
    "\n",
    "function model(par, x)\n",
    "    scale = try par[1] catch; par[1][1] end\n",
    "    σ     = try par[2] catch; par[2][1] end\n",
    "    μ     = try par[3] catch; par[3][1] end\n",
    "    return @. scale * exp(-0.5 * ((x - μ)^2) / (σ^2)) / (sqrt(2 * π * σ^2))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in [6]#0:1:36\n",
    "# ch = 19\n",
    "    files = glob(base_path * lpad(ch, 2, \"0\") * \"-\" * channel_to_name[ch] * \"/*.h5\");\n",
    "    files = get_share_for_worker(files, num_workers, this);\n",
    "    result = Table(energy = [], run = [], channel = [], AoEvetoed = [], datasetID = [], AoEclassifier = [], A = [], E = [], waveform = [])\n",
    "    cal[channel_to_name[ch]] = Dict()\n",
    "\n",
    "    @showprogress 1 \"Collecting Tl events for detector $ch ...\" for file in files\n",
    "        data = HDF5.h5open(file, \"r\") do h5f\n",
    "            LegendHDF5IO.readdata(h5f, \"data\")\n",
    "        end;\n",
    "        append!(result, data |> @filter(E - ΔE < _.energy < E + ΔE) |> Table)\n",
    "    end\n",
    "\n",
    "    for run in unique(result.run)\n",
    "            data = result |> @filter(_.run == run &&  maximum(_.waveform.value) > 100) |> Table #Int(_.datasetID) == 0 &&\n",
    "        if size(data,1) > 100\n",
    "            A_max = []\n",
    "            map(x-> push!(A_max, get_avg_maximum(x.waveform.value, 5)/x.energy), data);\n",
    "            A_max = A_max[findall(x->x > mean(A_max) - 3 * std(A_max), A_max)]\n",
    "            hist = fit(Histogram, A_max, minimum(A_max):0.00025:maximum(A_max))\n",
    "\n",
    "            likelihood = let h = hist, f = model\n",
    "                # Histogram counts for each bin as an array:\n",
    "                observed_counts = h.weights\n",
    "\n",
    "                # Histogram binning:\n",
    "                bin_edges = h.edges[1]\n",
    "                bin_edges_left = bin_edges[1:end-1]\n",
    "                bin_edges_right = bin_edges[2:end]\n",
    "                bin_widths = bin_edges_right - bin_edges_left\n",
    "                bin_centers = (bin_edges_right + bin_edges_left) / 2\n",
    "\n",
    "                params -> begin\n",
    "                    # Log-likelihood for a single bin:\n",
    "                    function bin_log_likelihood(i)\n",
    "                        # Simple mid-point rule integration of fit function `f` over bin:\n",
    "                        expected_counts = bin_widths[i] * f(params, bin_centers[i])\n",
    "                        logpdf(Poisson(expected_counts), observed_counts[i])\n",
    "                    end\n",
    "\n",
    "                    # Sum log-likelihood over bins:\n",
    "                    idxs = eachindex(observed_counts)\n",
    "                    ll_value = bin_log_likelihood(idxs[1])\n",
    "                    for i in idxs[2:end]\n",
    "                        ll_value += bin_log_likelihood(i)\n",
    "                    end\n",
    "\n",
    "                    # Wrap `ll_value` in `LogDVal` so BAT knows it's a log density-value.\n",
    "                    return LogDVal(ll_value)\n",
    "                end\n",
    "            end\n",
    "            Amax = maximum(A_max)\n",
    "            Amin = minimum(A_max)\n",
    "            prior = NamedTupleDist(\n",
    "                scale = sum(hist.weights)*0.75..sum(hist.weights)*1.25,\n",
    "                σ = 0.001..0.01,\n",
    "                µ = Amin..Amax\n",
    "            )\n",
    "            parshapes = varshape(prior)\n",
    "            posterior = PosteriorDensity(likelihood, prior);\n",
    "            samples = bat_sample(posterior, 10^5, MCMCSampling(sampler = MetropolisHastings(), nchains = 4)).result\n",
    "\n",
    "            y_fit = model(mode(samples)[1], midpoints(hist.edges[1]))\n",
    "            y_fit ./= sum(y_fit)\n",
    "            y_fit .*= sum(hist.weights)\n",
    "            p = plot(hist, st=:step, label=\"run\" * lpad(run, 4, \"0\"))\n",
    "            p = plot!(midpoints(hist.edges[1]), y_fit, label=\"Fit\")\n",
    "            p = vline!([mode(samples)[1].µ], label=\"Mean\")\n",
    "            p = plot!(size=(800,600), xlabel=\"Pulse amplitude / energy [ADC/keV]\", ylabel=\"Samples\")\n",
    "            filename = plots_base_path * \"Tl_FEP/\" * lpad(ch, 2, \"0\") * \"-\" * channel_to_name[ch] * \"/run\" * lpad(run, 4, \"0\") * \"-pulse_amplitude_over_E.png\"\n",
    "            !isdir(dirname(filename)) ? mkpath(dirname(filename)) : \"\"\n",
    "            savefig(p, filename)\n",
    "            IJulia.clear_output(true)\n",
    "            display(p)\n",
    "            cal[channel_to_name[ch]][\"run\" * lpad(run, 4, \"0\")] = [mode(samples)[1].µ, std(samples)[1].µ]\n",
    "        else\n",
    "            @info(\"Not enough data for run\" * lpad(run, 4, \"0\"))\n",
    "        end\n",
    "        open(\"../dicts/A_cal.json\", \"w\") do f\n",
    "            JSON.print(f, cal, 4)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = 6\n",
    "files = glob(base_path * lpad(ch, 2, \"0\") * \"-\" * channel_to_name[ch] * \"/*.h5\");\n",
    "files = get_share_for_worker(files, num_workers, this);\n",
    "result = Table(energy = [], run = [], channel = [], AoEvetoed = [], datasetID = [], AoEclassifier = [], A = [], E = [], waveform = [])\n",
    "cal[channel_to_name[ch]] = Dict()\n",
    "\n",
    "pro = Progress(length(files), dt=0.5,\n",
    "                barglyphs=BarGlyphs('|','█', ['▁' ,'▂' ,'▃' ,'▄' ,'▅' ,'▆', '▇'],' ','|',),\n",
    "                barlen=10);\n",
    "for file in files\n",
    "    data = HDF5.h5open(file, \"r\") do h5f\n",
    "        LegendHDF5IO.readdata(h5f, \"data\")\n",
    "    end;\n",
    "    append!(result, data |> @filter(E - ΔE < _.energy < E + ΔE) |> Table)\n",
    "    next!(pro)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in unique(result.run)\n",
    "#     run = unique(result.run)[i]\n",
    "    data = result |> @filter(_.run == run&& maximum(_.waveform.value) > 100) |> Table# && Int(_.datasetID) == 0 \n",
    "    if size(data,1) > 100\n",
    "        A_max = []\n",
    "        map(x-> push!(A_max, get_avg_maximum(x.waveform.value, 5)/x.energy), data);\n",
    "        A_max = A_max[findall(x->x > mean(A_max) - 3 * std(A_max), A_max)]\n",
    "        hist = fit(Histogram, A_max, minimum(A_max):0.00025:maximum(A_max))\n",
    "\n",
    "        Amax = maximum(A_max)\n",
    "        Amin = minimum(A_max)\n",
    "        \n",
    "        prior = NamedTupleDist(\n",
    "            scale = sum(hist.weights)*0.75..sum(hist.weights)*1.25,\n",
    "            σ = 0.001..0.01,\n",
    "            µ = Amin..Amax\n",
    "        )\n",
    "        display(plot(hist, st=:step))\n",
    "        \n",
    "        samples = bat_fit(hist, model, prior; nsamples=5*10^4, nchains=4, params_first=true, norm_expected=false)\n",
    "\n",
    "        y_fit = model(mode(samples)[1], midpoints(hist.edges[1]))\n",
    "        y_fit ./= sum(y_fit)\n",
    "        y_fit .*= sum(hist.weights)\n",
    "        p = plot(hist, st=:step, label=\"run\" * lpad(run, 4, \"0\"))\n",
    "        p = plot!(midpoints(hist.edges[1]), y_fit, label=\"Fit\")\n",
    "        p = vline!([mode(samples)[1].µ], label=\"Mean\")\n",
    "        p = plot!(size=(800,600), xlabel=\"Pulse amplitude / energy [ADC/keV]\", ylabel=\"Samples\")\n",
    "        filename = plots_base_path * \"Tl_FEP/\" * lpad(ch, 2, \"0\") * \"-\" * channel_to_name[ch] * \"/run\" * lpad(run, 4, \"0\") * \"-pulse_amplitude_over_E.png\"\n",
    "        !isdir(dirname(filename)) ? mkpath(dirname(filename)) : \"\"\n",
    "        savefig(p, filename)\n",
    "        IJulia.clear_output(true)\n",
    "        display(p)\n",
    "        cal[channel_to_name[ch]][\"run\" * lpad(run, 4, \"0\")] = [mode(samples)[1].µ, std(samples)[1].µ]\n",
    "    else\n",
    "        @info(\"Not enough data for run\" * lpad(run, 4, \"0\"))\n",
    "    end\n",
    "    open(\"../dicts/A_cal.json\", \"w\") do f\n",
    "        JSON.print(f, cal, 4)\n",
    "    end\n",
    "end\n",
    "# i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.0",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
